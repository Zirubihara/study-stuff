# Performance Analysis: 1M Rows Dataset (1,000,000 rows)

**Dataset Size:** ~30 MB
**Test Date:** 2025-10-04
**Technologies Tested:** Pandas, Polars, PyArrow, Dask, PySpark

---

## Executive Summary

For a 1M row dataset, **Polars** delivers the best overall performance with **3.6x faster** processing than Pandas and the lowest memory footprint. PySpark shows significant overhead, making it unsuitable for datasets of this size.

### Quick Rankings (Best to Worst)

1. **ü•á Polars** - 0.42s total time, 59 MB memory
2. **ü•à PyArrow** - 1.04s total time, 44 MB memory
3. **ü•â Pandas** - 1.51s total time, 124 MB memory
4. **Dask** - 3.93s total time, 47 MB memory
5. **PySpark** - 20.59s total time, 128 MB memory

---

## Detailed Performance Metrics

### Overall Performance Comparison

| Technology | Total Time (s) | Memory (MB) | Speed vs Pandas | Memory vs Pandas |
|------------|----------------|-------------|-----------------|------------------|
| **Polars** | 0.42 | 59 | **3.6x faster** | **52% less** |
| **PyArrow** | 1.04 | 44 | **1.5x faster** | **65% less** |
| **Pandas** | 1.51 | 124 | baseline | baseline |
| **Dask** | 3.93 | 47 | 2.6x slower | 62% less |
| **PySpark** | 20.59 | 128 | 13.6x slower | 3% more |

---

## Operation-by-Operation Breakdown

### 1. Loading (CSV Reading)

| Technology | Time (s) | Memory (MB) | Winner |
|------------|----------|-------------|--------|
| **PyArrow** | 0.18 | 162 | ‚úÖ Fastest |
| **Polars** | 0.19 | 101 | ü•à 2nd |
| **Pandas** | 1.07 | 73 | |
| **Dask** | 1.23 | 20 | ‚ö†Ô∏è Slowest (but low memory) |
| **PySpark** | 3.79 | -1 | ‚ö†Ô∏è Very slow |

**Winner:** PyArrow (0.18s) - fastest CSV reading
**Memory Winner:** Dask (20 MB) - lowest memory during load

### 2. Cleaning (Null Value Handling)

| Technology | Time (s) | Memory (MB) | Winner |
|------------|----------|-------------|--------|
| **Dask** | 0.00 | -1 | ‚úÖ Instant (lazy evaluation) |
| **Polars** | 0.004 | -14 | ü•à Very fast |
| **PyArrow** | 0.029 | 28 | |
| **PySpark** | 0.045 | 0 | |
| **Pandas** | 0.115 | 38 | ‚ö†Ô∏è Slowest |

**Winner:** Dask/Polars (near-instant)
**Note:** Polars and Dask use lazy evaluation, making cleaning nearly instant

### 3. Aggregation (Group By + Statistics)

| Technology | Time (s) | Memory (MB) | Winner |
|------------|----------|-------------|--------|
| **Dask** | 0.005 | 0.2 | ‚úÖ Fastest |
| **Polars** | 0.084 | 131 | |
| **Pandas** | 0.097 | 2.6 | |
| **PySpark** | 0.101 | 0 | |
| **PyArrow** | 0.484 | 23 | ‚ö†Ô∏è Slowest (fallback to Pandas) |

**Winner:** Dask (0.005s) - optimized lazy evaluation
**Note:** PyArrow falls back to Pandas for complex aggregations

### 4. Sorting

| Technology | Time (s) | Memory (MB) | Winner |
|------------|----------|-------------|--------|
| **Dask** | 0.00 | 0 | ‚úÖ Instant (lazy) |
| **PySpark** | 0.017 | 0 | |
| **Polars** | 0.082 | 107 | |
| **Pandas** | 0.114 | 46 | |
| **PyArrow** | 0.275 | 47 | ‚ö†Ô∏è Slowest |

**Winner:** Dask (lazy evaluation)
**Eager Winner:** PySpark (0.017s)

### 5. Filtering

| Technology | Time (s) | Memory (MB) | Winner |
|------------|----------|-------------|--------|
| **Polars** | 0.005 | 2 | ‚úÖ Fastest |
| **PyArrow** | 0.017 | 27 | |
| **Pandas** | 0.019 | 22 | |
| **Dask** | 1.27 | 5 | ‚ö†Ô∏è Very slow |
| **PySpark** | 2.24 | 0 | ‚ö†Ô∏è Very slow |

**Winner:** Polars (0.005s) - 4x faster than Pandas
**Note:** Dask and PySpark show distributed computing overhead

### 6. Correlation (Statistical Analysis)

| Technology | Time (s) | Memory (MB) | Winner |
|------------|----------|-------------|--------|
| **PyArrow** | 0.055 | 0.02 | ‚úÖ Fastest |
| **Polars** | 0.056 | 62 | ü•à Very close |
| **Pandas** | 0.096 | 0.07 | |
| **Dask** | 1.42 | 1.6 | |
| **PySpark** | 14.39 | -1 | ‚ö†Ô∏è 250x slower! |

**Winner:** PyArrow/Polars (0.05s)
**Critical:** PySpark performs terribly on correlation for small datasets

---

## Technology-Specific Analysis

### ü•á Polars - **RECOMMENDED for 1M datasets**

**Strengths:**
- ‚úÖ **Best overall performance** (0.42s total)
- ‚úÖ **Lowest memory usage** (59 MB)
- ‚úÖ **Excellent at filtering** (0.005s)
- ‚úÖ **Fast loading** (0.19s)
- ‚úÖ **Modern, clean API**

**Weaknesses:**
- ‚ö†Ô∏è Slightly slower aggregation than Dask (but Dask is lazy)

**Use When:**
- You want the fastest real-world performance
- Memory efficiency matters
- Working with 100K - 10M row datasets
- Building production data pipelines

**Computing Resources Required:**
- **CPU:** Any modern CPU (2+ cores)
- **RAM:** 500 MB minimum
- **Disk:** Fast SSD beneficial

---

### ü•à PyArrow - **Good for numerical operations**

**Strengths:**
- ‚úÖ **Fastest CSV loading** (0.18s)
- ‚úÖ **Lowest memory footprint** (44 MB)
- ‚úÖ **Excellent correlation performance** (0.055s)
- ‚úÖ **Columnar format efficiency**

**Weaknesses:**
- ‚ö†Ô∏è **Slow aggregation** (0.484s) - falls back to Pandas
- ‚ö†Ô∏è **Slower sorting** (0.275s)
- ‚ö†Ô∏è Limited functionality without Pandas fallback

**Use When:**
- Heavy numerical computations
- Need Apache Arrow compatibility
- Working with columnar data formats (Parquet)
- Pure read-heavy workloads

**Computing Resources Required:**
- **CPU:** 2+ cores
- **RAM:** 400 MB minimum
- **Disk:** Any

---

### ü•â Pandas - **Industry standard**

**Strengths:**
- ‚úÖ **Well-documented** and widely known
- ‚úÖ **Rich ecosystem** of libraries
- ‚úÖ **Consistent performance** across operations
- ‚úÖ **Good for quick prototyping**

**Weaknesses:**
- ‚ö†Ô∏è **Slower than Polars** (3.6x)
- ‚ö†Ô∏è **2x more memory** than Polars (124 MB vs 59 MB)
- ‚ö†Ô∏è **Slow loading** (1.07s)
- ‚ö†Ô∏è **Slow cleaning** (0.115s)

**Use When:**
- Team already knows Pandas well
- Using Pandas-specific libraries (scikit-learn integration)
- Dataset is small (< 500K rows)
- Rapid prototyping

**Computing Resources Required:**
- **CPU:** 2+ cores
- **RAM:** 1 GB minimum
- **Disk:** Any

---

### Dask - **Not recommended for 1M datasets**

**Strengths:**
- ‚úÖ **Instant lazy operations** (cleaning, sorting)
- ‚úÖ **Low memory** during loading (20 MB)
- ‚úÖ **Very fast aggregation** (0.005s with lazy eval)

**Weaknesses:**
- ‚ö†Ô∏è **Terrible filtering performance** (1.27s) - 250x slower than Polars
- ‚ö†Ô∏è **Slow correlation** (1.42s)
- ‚ö†Ô∏è **Overhead not justified** for small datasets
- ‚ö†Ô∏è **Total time 3.93s** - 10x slower than Polars

**Use When:**
- Data doesn't fit in memory (10GB+)
- Need distributed computing
- Scaling Pandas code to larger datasets
- **NOT for 1M row datasets**

**Computing Resources Required:**
- **CPU:** 4+ cores (to benefit from parallelism)
- **RAM:** 2+ GB
- **Disk:** Fast I/O

---

### PySpark - **AVOID for 1M datasets**

**Strengths:**
- ‚úÖ Built for distributed computing
- ‚úÖ Can handle massive datasets (100M+ rows)

**Weaknesses:**
- ‚ö†Ô∏è **Terrible performance** on 1M dataset (20.59s total)
- ‚ö†Ô∏è **48x slower than Polars**
- ‚ö†Ô∏è **Huge startup overhead** (3.79s just to load)
- ‚ö†Ô∏è **Correlation takes 14.4 seconds** (258x slower than Polars!)
- ‚ö†Ô∏è **Filtering takes 2.24 seconds** (450x slower than Polars!)
- ‚ö†Ô∏è JVM startup cost not justified

**Use When:**
- Dataset is truly massive (100M+ rows, 3GB+)
- Have a Spark cluster
- **NEVER for datasets under 10M rows**

**Computing Resources Required:**
- **CPU:** 8+ cores (cluster recommended)
- **RAM:** 4+ GB
- **Disk:** Distributed storage
- **JVM:** Java 11+ required

---

## Recommendations by Use Case

### For Data Scientists (Interactive Analysis)
**Use Polars** - Best balance of speed and memory, easy to learn

### For Production ETL Pipelines
**Use Polars** - Fast, memory-efficient, reliable

### For Machine Learning Preprocessing
**Use Polars** or **Pandas** - Both work well with scikit-learn

### For Apache Ecosystem Integration
**Use PyArrow** - Native compatibility with Parquet/Arrow formats

### For Legacy Code Migration
**Use Pandas** initially, then migrate to Polars when performance matters

### For 1M Row Datasets - DO NOT USE:
- ‚ùå **Dask** - 10x slower than Polars, no benefit
- ‚ùå **PySpark** - 48x slower than Polars, massive overhead

---

## Hardware Recommendations

### Minimum System Requirements (1M rows)
- **CPU:** Dual-core processor
- **RAM:** 2 GB
- **Storage:** 100 MB free space

### Recommended System (1M rows)
- **CPU:** Quad-core processor (Intel i5/AMD Ryzen 5 or better)
- **RAM:** 4-8 GB
- **Storage:** SSD with 500 MB free space

### Optimal System (1M rows)
- **CPU:** 6+ core processor
- **RAM:** 16 GB
- **Storage:** NVMe SSD

**Note:** For 1M row datasets, even modest hardware performs well with Polars/PyArrow.

---

## Key Takeaways for Your Thesis

1. **Polars is the clear winner** for 1M row datasets across almost all operations
2. **PyArrow excels at I/O** (loading) and basic numerical operations
3. **Pandas is viable** but 3.6x slower and uses 2x more memory
4. **Dask overhead isn't justified** for datasets that fit in memory
5. **PySpark should be avoided** entirely for small datasets (massive overhead)
6. **Memory efficiency matters** - Polars uses 52% less RAM than Pandas
7. **Operation-specific optimizations** - Different libraries excel at different tasks

---

**For academic citation:**
> "Performance benchmarking on a 1M row dataset demonstrated that Polars achieved 3.6x speedup over Pandas while consuming 52% less memory (59 MB vs 124 MB), making it the optimal choice for medium-sized data processing tasks on modern workstations."

